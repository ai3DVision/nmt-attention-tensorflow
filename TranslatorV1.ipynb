{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import collections\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=200)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.reader import europarl_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.nmt_graph import NMTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_dict_contents(d):\n",
    "    for k, v in d.items():\n",
    "        for k2, v2 in v.items():\n",
    "            print('{0: <30}: type={1: <30}{2}{3}'.format(\n",
    "                '{0}.{1}'.format(k, k2),\n",
    "                str(type(v2)),\n",
    "                ' shape={0}'.format(v2.shape) if isinstance(v2, np.ndarray) else '',\n",
    "                ' len={0}, contents type={1}'.format(\n",
    "                    len(v2),\n",
    "                    type(v2[0])\n",
    "                ) if isinstance(v2, list) else '',\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unvectorize_sentence(sentence, idx2word):\n",
    "    return ' '.join([idx2word[i] for i in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_group(data, group_num, num_samples=10):\n",
    "    samples = np.random.choice(len(data['train']['X'][group_num]), size=num_samples)\n",
    "    for sample in samples:\n",
    "        print(unvectorize_sentence(data['train']['X'][group_num][sample], data['vocab']['lang1_idx2word']))\n",
    "        print(unvectorize_sentence(data['train']['y'][group_num][sample], data['vocab']['lang2_idx2word']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = europarl_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.lang1_idx2word          : type=<class 'list'>                 len=44247, contents type=<class 'str'>\n",
      "vocab.lang1_word2idx          : type=<class 'dict'>                \n",
      "vocab.lang2_idx2word          : type=<class 'list'>                 len=93799, contents type=<class 'str'>\n",
      "vocab.lang2_word2idx          : type=<class 'dict'>                \n",
      "train.X                       : type=<class 'list'>                 len=31, contents type=<class 'numpy.ndarray'>\n",
      "train.y                       : type=<class 'list'>                 len=31, contents type=<class 'numpy.ndarray'>\n",
      "val.X                         : type=<class 'numpy.ndarray'>        shape=(160000, 882)\n",
      "val.y                         : type=<class 'list'>                 len=160000, contents type=<class 'str'>\n",
      "test.X                        : type=<class 'numpy.ndarray'>        shape=(160209, 684)\n",
      "test.y                        : type=<class 'list'>                 len=160209, contents type=<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "show_dict_contents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((5889, 3), (5889, 30)),\n",
       " ((1852, 4), (1852, 25)),\n",
       " ((5880, 5), (5880, 26)),\n",
       " ((6132, 6), (6132, 32)),\n",
       " ((15746, 7), (15746, 32)),\n",
       " ((18777, 8), (18777, 30)),\n",
       " ((22049, 9), (22049, 31)),\n",
       " ((27057, 10), (27057, 32)),\n",
       " ((30250, 11), (30250, 32)),\n",
       " ((33015, 12), (33015, 31)),\n",
       " ((35229, 13), (35229, 32)),\n",
       " ((38235, 14), (38235, 32)),\n",
       " ((40093, 15), (40093, 32)),\n",
       " ((42081, 16), (42081, 32)),\n",
       " ((43547, 17), (43547, 32)),\n",
       " ((44804, 18), (44804, 32)),\n",
       " ((46057, 19), (46057, 32)),\n",
       " ((46366, 20), (46366, 32)),\n",
       " ((46773, 21), (46773, 32)),\n",
       " ((46944, 22), (46944, 32)),\n",
       " ((46618, 23), (46618, 32)),\n",
       " ((45600, 24), (45600, 32)),\n",
       " ((44575, 25), (44575, 32)),\n",
       " ((43294, 26), (43294, 32)),\n",
       " ((41318, 27), (41318, 32)),\n",
       " ((38765, 28), (38765, 32)),\n",
       " ((35988, 29), (35988, 32)),\n",
       " ((32868, 30), (32868, 32)),\n",
       " ((28754, 31), (28754, 32)),\n",
       " ((24893, 32), (24893, 32))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.shape, y.shape) for x, y in sorted(zip(data['train']['X'], data['train']['y']), key=lambda t: t[0].shape[1]) if x.shape[1] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> <unk> who ? &apos; <eos>\n",
      "<bos> &quot; Wer &apos; ich &apos; ? &quot; <eos> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "<bos> ( Standing ovation ) <eos>\n",
      "<bos> ( Die Mitglieder des Parlaments erheben sich und spenden Beifall . ) <eos> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "<bos> - Before the vote <eos>\n",
      "<bos> - Vor der Abstimmung <eos> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_group(data, 0, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = NMTModel(data['vocab']['lang1_idx2word'], data['vocab']['lang2_idx2word'], 64, 256)\n",
    "all_graphs = model.make_all_graphs(32, data['train']['X'], data['train']['y'])\n",
    "writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
