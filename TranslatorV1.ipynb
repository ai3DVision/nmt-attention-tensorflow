{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import collections\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=200)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.reader import europarl_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.nmt_graph import NMTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_dict_contents(d):\n",
    "    for k, v in d.items():\n",
    "        for k2, v2 in v.items():\n",
    "            print('{0: <30}: type={1: <30}{2}{3}'.format(\n",
    "                '{0}.{1}'.format(k, k2),\n",
    "                str(type(v2)),\n",
    "                ' shape={0}'.format(v2.shape) if isinstance(v2, np.ndarray) else '',\n",
    "                ' len={0}, contents type={1}'.format(\n",
    "                    len(v2),\n",
    "                    type(v2[0])\n",
    "                ) if isinstance(v2, list) else '',\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unvectorize_sentence(sentence, idx2word):\n",
    "    return ' '.join([idx2word[i] for i in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_group(data, group_num, num_samples=10):\n",
    "    samples = np.random.choice(len(data['train']['X'][group_num]), size=num_samples)\n",
    "    for sample in samples:\n",
    "        print(unvectorize_sentence(data['train']['X'][group_num][sample], data['vocab']['lang1_idx2word']))\n",
    "        print(unvectorize_sentence(data['train']['y'][group_num][sample], data['vocab']['lang2_idx2word']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.lang1_idx2word          : type=<class 'list'>                 len=93800, contents type=<class 'str'>\n",
      "vocab.lang1_word2idx          : type=<class 'dict'>                \n",
      "vocab.lang2_idx2word          : type=<class 'list'>                 len=44248, contents type=<class 'str'>\n",
      "vocab.lang2_word2idx          : type=<class 'dict'>                \n",
      "train.X                       : type=<class 'list'>                 len=4, contents type=<class 'numpy.ndarray'>\n",
      "train.y                       : type=<class 'list'>                 len=4, contents type=<class 'numpy.ndarray'>\n",
      "val.X                         : type=<class 'numpy.ndarray'>        shape=(160000, 604)\n",
      "val.y                         : type=<class 'list'>                 len=160000, contents type=<class 'str'>\n",
      "test.X                        : type=<class 'numpy.ndarray'>        shape=(160209, 640)\n",
      "test.y                        : type=<class 'list'>                 len=160209, contents type=<class 'str'>\n",
      "[((63624, 8), (63624, 32)), ((297434, 16), (297434, 32)), ((377096, 24), (377096, 32)), ((241295, 32), (241295, 32))]\n"
     ]
    }
   ],
   "source": [
    "data = europarl_raw_data()\n",
    "show_dict_contents(data)\n",
    "print(\n",
    "    [(x.shape, y.shape) for x, y in sorted(zip(data['train']['X'], data['train']['y']), key=lambda t: t[0].shape[1]) if x.shape[1] > 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<bos> It is an ambitious project for 2010 . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "<bos> ( Beifall ) <eos> <pad> <pad> <pad>\n",
      "<bos> ( Applause ) <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "<bos> Vielen Dank . <eos> <pad> <pad> <pad>\n",
      "<bos> Thank you very much . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "<bos> Die Niederlande waren stets proeurop√§isch . <eos>\n",
      "<bos> The Netherlands has always been a pro-European country . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "<bos> Daran besteht kein Zweifel . <eos> <pad>\n",
      "<bos> Very well , that is how it should be . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_group(data, 0, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63624, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['X'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = NMTModel(data['vocab']['lang1_idx2word'], data['vocab']['lang2_idx2word'], 128, 512)\n",
    "all_graphs = model.make_all_graphs(16, data['train']['X'], data['train']['y'])\n",
    "eval_graph = model.make_eval_graph(16, data['train']['X'][0].shape[1] - 2, 32, data['vocab']['lang2_word2idx']['<bos>'])\n",
    "writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholders.inputs           : type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "placeholders.targets          : type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "placeholders.learning_rate    : type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "placeholders.max_norm         : type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "outputs.loss                  : type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "outputs.num_correct_predictions: type=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "train_ops.train_op            : type=<class 'tensorflow.python.framework.ops.Operation'>\n",
      "train_ops.gradient_global_norm: type=<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "show_dict_contents(all_graphs[0]['inputs_and_outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INITIAL_LR=5e0\n",
    "MAX_NORM=1\n",
    "with tf.Session() as sess:\n",
    "    run_id = time.time()\n",
    "    writer = tf.summary.FileWriter('logs/{0}'.format(run_id), sess.graph)\n",
    "    coord = tf.train.Coordinator()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    learning_rate = INITIAL_LR\n",
    "    max_norm = MAX_NORM\n",
    "    training_outputs = {\n",
    "        **all_graphs[0]['inputs_and_outputs']['outputs'],\n",
    "        **all_graphs[0]['inputs_and_outputs']['train_ops'],\n",
    "    }\n",
    "    for i in range(50):\n",
    "        for j in range(10):\n",
    "            start_idx = 0 * 16\n",
    "            end_idx = (0+1) * 16\n",
    "            inputs = data['train']['X'][0][start_idx:end_idx, 1:-1]\n",
    "            targets = data['train']['y'][0][start_idx:end_idx]\n",
    "            outputs = sess.run(\n",
    "                training_outputs,\n",
    "                feed_dict={\n",
    "                    all_graphs[0]['inputs_and_outputs']['placeholders']['inputs']: inputs,\n",
    "                    all_graphs[0]['inputs_and_outputs']['placeholders']['targets']: targets,\n",
    "                    all_graphs[0]['inputs_and_outputs']['placeholders']['learning_rate']: learning_rate * (10.0 / (10.0 + np.sqrt(i))),\n",
    "                    all_graphs[0]['inputs_and_outputs']['placeholders']['max_norm']: max_norm,\n",
    "                }\n",
    "            )\n",
    "        eval_outputs = sess.run(\n",
    "            eval_graph['outputs']['outputs'],\n",
    "            feed_dict={\n",
    "                eval_graph['placeholders']['inputs']: inputs,\n",
    "            }\n",
    "        )\n",
    "        print('-' * 40)\n",
    "        print('i = {0}'.format(i))\n",
    "        print(outputs)\n",
    "        for sample in range(start_idx, end_idx):\n",
    "            print(unvectorize_sentence(data['train']['X'][0][sample], data['vocab']['lang1_idx2word']))\n",
    "            print(unvectorize_sentence(data['train']['y'][0][sample], data['vocab']['lang2_idx2word']))\n",
    "            print(unvectorize_sentence(eval_outputs[sample - start_idx], data['vocab']['lang2_idx2word']))\n",
    "            print()\n",
    "        print('-' * 40)\n",
    "            \n",
    "\n",
    "    # Bookkeeping        \n",
    "    writer.close()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    run_id = time.time()\n",
    "    writer = tf.summary.FileWriter('logs/{0}'.format(run_id), sess.graph)\n",
    "    coord = tf.train.Coordinator()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    learning_rate = INITIAL_LR\n",
    "    max_norm = MAX_NORM\n",
    "    for i in range(1): #NUM_EPOCHS_TOTAL):\n",
    "#         if i >= NUM_EPOCHS_INIT_LR:\n",
    "#             learning_rate *= LR_DECAY_RATE\n",
    "        for batch_idx, (inputs, targets) in enumerate(generate_epoch(X_train, BATCH_SIZE, NUM_STEPS)):\n",
    "            outputs = sess.run(\n",
    "                training_outputs,\n",
    "                feed_dict={\n",
    "                    placeholders['inputs']: inputs,\n",
    "                    placeholders['targets']: targets,\n",
    "                    placeholders['learning_rate']: learning_rate,\n",
    "                    placeholders['max_norm']: max_norm,\n",
    "                }\n",
    "            )\n",
    "            if (batch_idx % 64 == 63):\n",
    "                print('step: {0}    loss: {1}    gradient norm: {2}     correct words: {3}'.format(\n",
    "                    batch_idx+1,\n",
    "                    outputs['loss'],\n",
    "                    outputs['gradient_global_norm'],\n",
    "                    outputs['num_correct_predictions'],\n",
    "                ))\n",
    "                \n",
    "        total_loss, total_batches = 0, 0\n",
    "        for inputs, targets in generate_epoch(X_val, BATCH_SIZE, NUM_STEPS):\n",
    "            outputs = sess.run(\n",
    "                summary_nodes,\n",
    "                feed_dict={\n",
    "                    placeholders['inputs']: inputs,\n",
    "                    placeholders['targets']: targets\n",
    "                },\n",
    "            )\n",
    "            total_loss += outputs['loss']\n",
    "            total_batches += 1\n",
    "        print('validation perplexity:', np.exp(total_loss / total_batches))\n",
    "        total_loss, total_batches = 0, 0\n",
    "        for inputs, targets in generate_epoch(X_test, BATCH_SIZE, NUM_STEPS):\n",
    "            outputs = sess.run(\n",
    "                summary_nodes,\n",
    "                feed_dict={\n",
    "                    placeholders['inputs']: inputs,\n",
    "                    placeholders['targets']: targets\n",
    "                },\n",
    "            )\n",
    "            total_loss += outputs['loss']\n",
    "            total_batches += 1\n",
    "        print('test perplexity:', np.exp(total_loss / total_batches))\n",
    "\n",
    "    # Bookkeeping        \n",
    "    writer.close()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
