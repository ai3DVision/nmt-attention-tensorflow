{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=200)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.reader import ptb_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, vocab_size = ptb_raw_data('bigdata/simple-examples/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shoutout to: \n",
    "# https://stackoverflow.com/questions/41695893/tensorflow-conditionally-add-variable-scope\n",
    "class empty_scope():\n",
    " def __init__(self):\n",
    "     pass\n",
    " def __enter__(self):\n",
    "     pass\n",
    " def __exit__(self, type, value, traceback):\n",
    "     pass\n",
    "\n",
    "def cond_name_scope(scope):\n",
    "    return empty_scope() if scope is None else tf.name_scope(scope)\n",
    "\n",
    "def cond_variable_scope(scope):\n",
    "    return empty_scope() if scope is None else tf.variable_scope(scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ptb_batcher(raw_data, batch_size, num_steps):\n",
    "    \"\"\"Return a batch of data.\n",
    "\n",
    "    Equivalent of ptb_producer that I wrote to understand all the TF concepts.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('batcher'):\n",
    "        tf_raw_data = tf.convert_to_tensor(\n",
    "            raw_data,\n",
    "            name='raw_data',\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "        data_len = tf.size(\n",
    "            tf_raw_data,\n",
    "            name='num_elems'\n",
    "        )\n",
    "        num_batches = tf.floordiv(\n",
    "            data_len, batch_size,\n",
    "            name='num_batches'\n",
    "        )\n",
    "        data = tf.reshape(\n",
    "            tf_raw_data[:batch_size * num_batches],\n",
    "            [batch_size, num_batches],\n",
    "            name='data'\n",
    "        )\n",
    "        batches_per_epoch = tf.floordiv(\n",
    "            num_batches - 1, num_steps,\n",
    "            name='batches_per_epoch'\n",
    "        )\n",
    "        tf_queue = tf.train.range_input_producer(\n",
    "            limit=batches_per_epoch, shuffle=False\n",
    "        )\n",
    "        i = tf_queue.dequeue(name='iter_idx')\n",
    "        x = tf.identity(\n",
    "            data[:, (i * num_steps):((i+1) * num_steps)], \n",
    "            name='x'\n",
    "        )\n",
    "        x.set_shape([batch_size, num_steps])\n",
    "        y = tf.identity(\n",
    "            data[:, (1 + i * num_steps):(1 + (i+1) * num_steps)],\n",
    "            name='y'\n",
    "        )\n",
    "        y.set_shape([batch_size, num_steps])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gru_update(x_t, h_t_minus_1, gru_params, timestep=None):\n",
    "    U_z, W_z, b_z = gru_params['U_z'], gru_params['W_z'], gru_params['b_z']\n",
    "    U_r, W_r, b_r = gru_params['U_r'], gru_params['W_r'], gru_params['b_r']\n",
    "    U_h, W_h, b_h = gru_params['U_h'], gru_params['W_h'], gru_params['b_h']\n",
    "    with tf.name_scope('gru_calculations'):\n",
    "        r_t = tf.sigmoid(\n",
    "            tf.matmul(x_t, W_r) + tf.matmul(h_t_minus_1, U_r) + b_r,\n",
    "            name='r' + (\n",
    "                '_{0}'.format(timestep) if timestep is not None else ''\n",
    "            ),\n",
    "        )\n",
    "        z_t = tf.sigmoid(\n",
    "            tf.matmul(x_t, W_z) + tf.matmul(h_t_minus_1, U_z) + b_z,\n",
    "            name='z' + (\n",
    "                '_{0}'.format(timestep) if timestep is not None else ''\n",
    "            ),\n",
    "        )\n",
    "        h_tilde_t = tf.tanh(\n",
    "            tf.matmul(x_t, W_h) + tf.matmul(h_t_minus_1 * r_t, U_h) + b_h,\n",
    "            name='h_tilde' + (\n",
    "                '_{0}'.format(timestep) if timestep is not None else ''\n",
    "            ),\n",
    "        )\n",
    "        h_t = z_t * h_t_minus_1 + (1 - z_t) * h_tilde_t\n",
    "    return h_t    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_rnn(vocab_size, embedding_size, hidden_size, batch_size, num_steps):\n",
    "    \"\"\"Simplified version of PTBModel\"\"\"\n",
    "    with tf.variable_scope(\n",
    "        'RNNParams',\n",
    "        reuse=False,\n",
    "        initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "    ):\n",
    "        embedding_matrix = tf.get_variable(\n",
    "            'embedding',\n",
    "            [vocab_size, embedding_size],\n",
    "            dtype=tf.float16,\n",
    "        )\n",
    "        gru_params = {\n",
    "            'U_z': tf.get_variable(\n",
    "                'U_z',\n",
    "                [hidden_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'W_z': tf.get_variable(\n",
    "                'W_z',\n",
    "                [embedding_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'b_z': tf.get_variable(\n",
    "                'b_z',\n",
    "                [hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'U_r': tf.get_variable(\n",
    "                'U_r',\n",
    "                [hidden_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'W_r': tf.get_variable(\n",
    "                'W_r',\n",
    "                [embedding_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'b_r': tf.get_variable(\n",
    "                'b_r',\n",
    "                [hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'U_h': tf.get_variable(\n",
    "                'U_h',\n",
    "                [hidden_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'W_h': tf.get_variable(\n",
    "                'W_h',\n",
    "                [embedding_size, hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'b_h': tf.get_variable(\n",
    "                'b_h',\n",
    "                [hidden_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "        }\n",
    "        softmax_params = {\n",
    "            'W': tf.get_variable(\n",
    "                'softmax_w',\n",
    "                [hidden_size, vocab_size],\n",
    "                dtype=tf.float16,\n",
    "            ),\n",
    "            'b': tf.get_variable(\n",
    "                'softmax_b',\n",
    "                [vocab_size],\n",
    "                dtype=tf.float16,\n",
    "            )\n",
    "        }\n",
    "\n",
    "    with tf.name_scope('RNN'):\n",
    "        input_sequence = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[batch_size, num_steps],\n",
    "            name='input_sequence',\n",
    "        )\n",
    "        embedded_inputs = tf.nn.embedding_lookup(\n",
    "            embedding_matrix,\n",
    "            input_sequence,\n",
    "            name='embedded_inputs',\n",
    "        )\n",
    "        h_start = tf.zeros(\n",
    "            [batch_size, hidden_size],\n",
    "            name='h_start',\n",
    "            dtype=tf.float16,\n",
    "        )\n",
    "        h_prev = h_start\n",
    "        h_states = []\n",
    "        for i in range(num_steps):\n",
    "            h_states.append(gru_update(\n",
    "                embedded_inputs[:, i, :],\n",
    "                h_prev,\n",
    "                gru_params,\n",
    "                i\n",
    "            ))\n",
    "            h_prev = h_states[-1]\n",
    "            \n",
    "        # h_states is a list of tensors, each of which has shape\n",
    "        # (batch_size, hidden_size)\n",
    "        #\n",
    "        # we ultimately want to end up with something of shape \n",
    "        # (batch_size, num_steps, vocab_size)\n",
    "        # \n",
    "        # To see why the steps below work, try the following.\n",
    "        # (In this example, batch_size is 3, hidden_size = 4, num_steps = 2)\n",
    "        # \n",
    "        # m1 = tf.constant(np.reshape(np.arange(12),(3,4)))\n",
    "        # m2 = tf.constant(6 + np.reshape(np.arange(12),(3,4)))\n",
    "        # concatenated_ms = tf.concat([m1, m2], axis=1)\n",
    "        # skinny_ms = tf.reshape(concatenated_ms, [-1, 4])\n",
    "        # reshaped_ms = tf.reshape(skinny_ms, [-1, 2, 4])\n",
    "        # with tf.Session() as sess:\n",
    "        #     for m in sess.run([\n",
    "        #         concatenated_ms,\n",
    "        #         skinny_ms,\n",
    "        #         reshaped_ms\n",
    "        #     ]):\n",
    "        #         print(m)\n",
    "        #         print()\n",
    "        #\n",
    "        # which prints\n",
    "        #\n",
    "        # [[ 0  1  2  3  6  7  8  9]\n",
    "        #  [ 4  5  6  7 10 11 12 13]\n",
    "        #  [ 8  9 10 11 14 15 16 17]]\n",
    "        #\n",
    "        # [[ 0  1  2  3]\n",
    "        #  [ 6  7  8  9]\n",
    "        #  [ 4  5  6  7]\n",
    "        #  [10 11 12 13]\n",
    "        #  [ 8  9 10 11]\n",
    "        #  [14 15 16 17]]\n",
    "        #\n",
    "        # [[[ 0  1  2  3]\n",
    "        #   [ 6  7  8  9]]\n",
    "        #\n",
    "        #  [[ 4  5  6  7]\n",
    "        #   [10 11 12 13]]\n",
    "        #\n",
    "        #  [[ 8  9 10 11]\n",
    "        #   [14 15 16 17]]]\n",
    "        #\n",
    "        # concatenated_states will have shape\n",
    "        # (batch_size, num_steps * hidden_size)\n",
    "        concatenated_states = tf.concat(\n",
    "            h_states,\n",
    "            axis=1,\n",
    "            name='concatenated_states'\n",
    "        )\n",
    "        # reshaped_states (which will get used for attention)\n",
    "        # will have have shape (batch_size, num_steps, hidden_size)\n",
    "        reshaped_states = tf.reshape(\n",
    "            concatenated_states,\n",
    "            [batch_size, num_steps, hidden_size],\n",
    "            name='reshaped_states',\n",
    "        )        \n",
    "        # long_and_skinny_states will have shape \n",
    "        # (batch_size * num_steps, hidden_size)\n",
    "        long_and_skinny_states = tf.reshape(\n",
    "            concatenated_states,\n",
    "            [batch_size * num_steps, hidden_size],\n",
    "            name='long_and_skinny_states',\n",
    "        )\n",
    "        # long_and_skinny_logits will have shape\n",
    "        # (batch_size * num_steps, vocab_size)\n",
    "        long_and_skinny_logits = tf.nn.xw_plus_b(\n",
    "            long_and_skinny_states,\n",
    "            softmax_params['W'],\n",
    "            softmax_params['b'],\n",
    "            name='long_and_skinny_logits',\n",
    "        )\n",
    "        # logits will have shape \n",
    "        # (batch_size, num_steps, vocab_size)\n",
    "        logits = tf.reshape(\n",
    "            long_and_skinny_logits,\n",
    "            [batch_size, num_steps, vocab_size],\n",
    "            name='logits'\n",
    "        )\n",
    "        \n",
    "    \n",
    "    return {\n",
    "        'inputs': {\n",
    "            'input_sequence': input_sequence,\n",
    "        },\n",
    "        'params': {\n",
    "            'embedding_matrix': embedding_matrix,\n",
    "            'gru_params': gru_params,\n",
    "            'softmax_params': softmax_params,\n",
    "        },\n",
    "        'outputs': {\n",
    "            'reshaped_states': reshaped_states,\n",
    "            'logits': logits,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_op(batch_size, num_steps, logits):\n",
    "    with tf.name_scope('train'):\n",
    "        targets = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[batch_size, num_steps],\n",
    "            name='target_sequence',\n",
    "        )\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits=logits,\n",
    "            targets=targets,\n",
    "            weights=tf.ones([\n",
    "                batch_size,\n",
    "                num_steps\n",
    "            ], dtype=tf.float16),\n",
    "            average_across_timesteps=True,\n",
    "            average_across_batch=True,\n",
    "            name='loss',\n",
    "        )\n",
    "        trainable_variables = tf.trainable_variables()\n",
    "        unclipped_gradients = tf.gradients(loss, trainable_variables)\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "            unclipped_gradients,\n",
    "            5.,\n",
    "            name='clipped_gradients'\n",
    "        )\n",
    "        optimizer = tf.train.GradientDescentOptimizer(1.0)\n",
    "        train_op = optimizer.apply_gradients(\n",
    "            zip(clipped_gradients, trainable_variables),\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        'inputs': {\n",
    "            'targets': targets,\n",
    "        },\n",
    "        'outputs': {\n",
    "            'loss': loss,\n",
    "            'train_op': train_op,\n",
    "        },\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE=128\n",
    "EMBEDDING_SIZE=8\n",
    "HIDDEN_SIZE=12\n",
    "BATCH_SIZE=4\n",
    "NUM_STEPS=16\n",
    "\n",
    "tf.reset_default_graph()\n",
    "my_rnn = make_rnn(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_steps=NUM_STEPS,\n",
    ")\n",
    "my_outputs = get_train_op(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_steps=NUM_STEPS,\n",
    "    logits=my_rnn['outputs']['logits'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8125\n",
      "3.3594\n",
      "3.0176\n",
      "2.7422\n",
      "2.5957\n",
      "2.4883\n",
      "1.6592\n",
      "1.2588\n",
      "0.98535\n",
      "0.84473\n",
      "{'embedding_matrix': array([[ -3.4351e-01,   5.5957e-01,   6.3965e-01, ...,  -3.0176e-01,  -8.9966e-02,   6.4307e-01],\n",
      "       [  4.4495e-02,   2.4719e-02,   1.7395e-02, ...,   2.8381e-03,  -2.6169e-02,  -2.6855e-02],\n",
      "       [ -3.6407e-02,   4.6204e-02,   1.4648e-03, ...,   1.0651e-02,   2.3132e-02,   2.6733e-02],\n",
      "       ..., \n",
      "       [  2.2278e-02,   2.0508e-02,  -2.3041e-02, ...,   9.1553e-05,   4.3030e-03,   4.3518e-02],\n",
      "       [  9.1187e-02,   1.6272e-01,   4.8926e-01, ...,  -2.7686e-01,  -4.0970e-03,  -1.6418e-01],\n",
      "       [ -7.4036e-02,  -1.3879e-01,   3.2520e-01, ...,  -2.6489e-01,  -1.0980e-01,   8.3923e-02]], dtype=float16), 'gru_params': {'U_z': array([[  1.7395e-01,  -4.5020e-01,  -8.7708e-02,   6.8420e-02,  -6.2866e-02,   6.0997e-03,   7.1955e-04,  -6.0205e-01,  -7.4072e-01,   4.4800e-01,  -4.4098e-02,   2.2400e-01],\n",
      "       [  7.1487e-03,   1.7273e-01,   5.3131e-02,  -6.6711e-02,  -2.0300e-01,  -3.3081e-01,  -3.8257e-01,   5.7178e-01,  -7.3047e-01,  -1.1725e-01,  -3.3643e-01,  -4.6906e-02],\n",
      "       [  3.8757e-02,  -3.9453e-01,  -2.2681e-01,   2.5952e-01,   4.0161e-01,   4.1675e-01,   4.9219e-01,  -4.3408e-01,   2.0154e-01,   2.7515e-01,   4.2920e-01,   1.7615e-01],\n",
      "       [ -1.4478e-01,  -4.0771e-01,   6.5575e-03,   1.5649e-01,   3.3252e-01,   1.4600e-01,   1.4722e-01,  -3.6206e-01,  -6.0156e-01,  -1.0933e-02,   1.4832e-01,  -3.7842e-02],\n",
      "       [  8.9648e-01,   5.6396e-01,   6.4355e-01,   8.8184e-01,   3.6279e-01,   2.4756e-01,   2.1863e-01,   5.1221e-01,  -1.1334e-01,   7.8027e-01,   1.9604e-01,   6.6602e-01],\n",
      "       [  1.0088e+00,   5.4395e-01,   7.1191e-01,   1.0654e+00,   5.6006e-01,   2.7783e-01,   3.5962e-01,   4.4556e-01,  -9.2407e-02,   1.0039e+00,   3.0176e-01,   8.2617e-01],\n",
      "       [  1.0186e+00,   5.5811e-01,   7.7100e-01,   9.9121e-01,   5.5713e-01,   3.0811e-01,   3.7476e-01,   3.6353e-01,  -1.4697e-01,   1.0742e+00,   3.4082e-01,   8.8477e-01],\n",
      "       [ -3.8818e-02,   1.6150e-01,  -3.3478e-02,  -5.0598e-02,  -2.0459e-01,  -4.6191e-01,  -4.7876e-01,   7.4316e-01,   5.4932e-01,  -1.3086e-01,  -3.6597e-01,  -1.0986e-01],\n",
      "       [ -1.6541e-01,   1.1743e-01,  -2.9175e-01,  -2.6392e-01,  -2.8613e-01,  -4.2041e-01,  -4.3945e-01,   9.3140e-02,   1.5547e+00,  -1.5601e-01,  -4.6313e-01,  -8.7097e-02],\n",
      "       [  2.8516e-01,   3.7476e-01,   2.0215e-01,  -2.7740e-02,  -1.4124e-01,   1.1932e-01,   7.3730e-02,   3.8379e-01,   8.0994e-02,  -3.3569e-02,   5.0751e-02,  -2.1265e-01],\n",
      "       [  1.0898e+00,   5.3027e-01,   7.4121e-01,   9.6533e-01,   5.8691e-01,   3.3936e-01,   3.8135e-01,   4.4141e-01,  -1.8530e-01,   1.0615e+00,   3.1055e-01,   8.6084e-01],\n",
      "       [  6.5674e-01,   1.1377e-01,   2.9126e-01,   3.3252e-01,  -5.2795e-02,   2.0032e-01,   1.3745e-01,   2.6660e-01,  -2.4622e-01,   4.5410e-01,   1.4087e-01,   2.2217e-01]], dtype=float16), 'W_z': array([[  1.6418e-01,   4.1168e-02,   6.6638e-05,   1.2369e-03,  -1.4420e-02,  -8.6548e-02,  -1.4514e-01,   3.4106e-01,  -1.8408e+00,   2.6108e-02,  -3.2715e-02,  -1.4880e-01],\n",
      "       [ -2.4744e-01,   2.2546e-01,  -6.6650e-02,   9.5276e-02,   3.2806e-02,   3.8300e-02,   1.8091e-01,   2.8076e-01,   1.5049e+00,  -1.3977e-01,  -1.8036e-02,  -2.8076e-03],\n",
      "       [ -4.9347e-02,   4.9878e-01,   2.3352e-01,  -4.7180e-02,   1.3135e-01,  -7.5317e-02,  -5.8868e-02,   9.6191e-01,   3.7720e-01,   2.7100e-02,  -1.7566e-01,   3.4619e-01],\n",
      "       [ -3.0762e-01,  -2.8397e-02,  -3.1934e-01,   8.7769e-02,  -2.2839e-01,   1.2268e-01,   1.1560e-01,   3.4448e-01,   4.2603e-01,  -3.2495e-01,  -3.5309e-02,  -4.8389e-01],\n",
      "       [ -2.3926e-02,   2.9102e-01,   1.2988e-01,   6.1066e-02,   1.2213e-01,   9.9411e-03,  -3.4576e-02,   3.8916e-01,  -3.0624e-02,  -4.1168e-02,  -5.6274e-02,   1.2732e-01],\n",
      "       [ -7.0618e-02,  -3.3984e-01,  -2.1643e-01,   4.0131e-02,  -2.3645e-01,   1.8143e-02,  -4.1618e-03,  -2.7954e-01,  -2.3010e-01,  -1.7725e-01,   9.8999e-02,  -3.7622e-01],\n",
      "       [ -9.4299e-02,  -9.5062e-03,  -6.3599e-02,  -4.7760e-03,  -3.3417e-02,   7.0862e-02,   1.3313e-02,   1.4478e-01,   4.9585e-01,  -1.1353e-01,  -3.6896e-02,  -9.7229e-02],\n",
      "       [ -1.5576e-01,   3.1799e-02,   6.6406e-02,  -3.7872e-02,  -1.9592e-02,   5.5389e-02,   9.4849e-02,  -2.9590e-01,   2.1934e+00,   9.7717e-02,  -8.4900e-02,   1.6028e-01]], dtype=float16), 'b_z': array([-1.8369, -1.0527, -1.9775, -1.3574, -0.3845, -0.0768, -0.0671, -0.8022, -0.7983, -1.6338, -0.1931, -1.208 ], dtype=float16), 'U_r': array([[ 0.0057,  0.0224, -0.0018,  0.2878,  0.2959,  0.2871,  0.2202,  0.0067, -0.0031,  0.2896,  0.27  ,  0.2947],\n",
      "       [-0.4431,  0.0457,  0.064 , -0.03  , -0.0381,  0.0567,  0.1012,  0.0337,  0.1454, -0.2422,  0.1095, -0.2156],\n",
      "       [ 0.468 ,  0.0901, -0.0688, -0.0277,  0.0671, -0.0464, -0.0101,  0.0554, -0.0244,  0.3975, -0.0237,  0.2069],\n",
      "       [ 0.5068,  0.0841, -0.0854, -0.0485,  0.2261,  0.2191,  0.2886,  0.0884,  0.0404,  0.3206,  0.2098,  0.1755],\n",
      "       [-0.4485, -0.355 , -0.426 , -0.4299, -0.3281, -0.3464, -0.3269, -0.3904, -0.4392, -0.3257, -0.3335, -0.2375],\n",
      "       [-0.4346, -0.4526, -0.6431, -0.4531, -0.323 , -0.2479, -0.3691, -0.5698, -0.4983, -0.2759, -0.3425, -0.2998],\n",
      "       [-0.3909, -0.3982, -0.5825, -0.4841, -0.2939, -0.2822, -0.3713, -0.5386, -0.5146, -0.3047, -0.2639, -0.2773],\n",
      "       [-0.5283,  0.062 ,  0.1205, -0.0687, -0.1512, -0.0265,  0.0795,  0.041 ,  0.1676, -0.3569, -0.0083, -0.2563],\n",
      "       [-0.3223,  0.3438,  0.2922,  0.0336,  0.0009,  0.1124,  0.1775,  0.3057,  0.2554, -0.3965,  0.0533, -0.2054],\n",
      "       [-0.1482, -0.2377, -0.0292, -0.2487, -0.23  , -0.261 , -0.2502, -0.2101, -0.1517, -0.1646, -0.1964, -0.0276],\n",
      "       [-0.4529, -0.4231, -0.6055, -0.4883, -0.2639, -0.2686, -0.3625, -0.5972, -0.5239, -0.3169, -0.3303, -0.2773],\n",
      "       [-0.3779, -0.3806, -0.252 , -0.3677, -0.3223, -0.3086, -0.3462, -0.3284, -0.3059, -0.1473, -0.2593, -0.1433]], dtype=float16), 'W_r': array([[-0.0367, -0.0105,  0.0613,  0.0246,  0.0532,  0.0414, -0.0005,  0.0325, -0.0359,  0.0597,  0.0242, -0.0277],\n",
      "       [-0.1074, -0.0598,  0.0275, -0.0406, -0.1522, -0.0663, -0.1182,  0.0575,  0.0448, -0.1114, -0.0567, -0.1528],\n",
      "       [-0.0251, -0.2079, -0.2097,  0.113 ,  0.2375,  0.1827,  0.2216, -0.2039, -0.2299,  0.0686,  0.272 ,  0.1813],\n",
      "       [-0.0887,  0.1693,  0.1925, -0.1577, -0.3906, -0.3059, -0.3589,  0.27  ,  0.3384, -0.3032, -0.4131, -0.3445],\n",
      "       [ 0.0378, -0.1694, -0.1222,  0.058 ,  0.0961,  0.1165,  0.1395, -0.132 , -0.1365,  0.0248,  0.1281,  0.0959],\n",
      "       [-0.1107,  0.2046,  0.1606, -0.0845, -0.2834, -0.198 , -0.2844,  0.2155,  0.1848, -0.2534, -0.2273, -0.259 ],\n",
      "       [-0.0275,  0.0475,  0.0536, -0.0249, -0.1089, -0.1055, -0.123 ,  0.0765,  0.0555, -0.0309, -0.1368, -0.1313],\n",
      "       [ 0.0349, -0.0676, -0.0198, -0.007 , -0.0451, -0.0222, -0.0216, -0.0927,  0.016 ,  0.0207,  0.0041, -0.0454]], dtype=float16), 'b_r': array([ 0.238 ,  0.6475,  0.8516,  0.4563,  0.2942,  0.2517,  0.3853,  0.7446,  0.7646,  0.1331,  0.3352,  0.1483], dtype=float16), 'U_h': array([[-0.2612, -0.748 ,  1.2227,  1.1611,  0.3796, -0.0032, -0.0955,  0.1263, -0.2507, -2.7344, -0.0173,  0.259 ],\n",
      "       [ 0.429 ,  1.2119, -0.2156, -0.5137, -0.2045, -0.0544, -0.0144,  2.0098,  1.4072, -0.8818, -0.0374, -0.5078],\n",
      "       [-0.8086, -2.6113,  0.8125,  0.7007,  0.543 ,  0.2328,  0.2396, -1.3105, -0.9067,  1.0684,  0.1885,  0.7661],\n",
      "       [-0.6479, -1.1641,  2.1523,  0.9238, -0.2141, -0.0559, -0.0265, -0.3989, -0.2189,  0.171 , -0.105 ,  0.0654],\n",
      "       [-0.6577,  0.6699, -0.856 , -0.9766,  0.8047,  0.54  ,  0.5269,  0.0861,  0.2751,  0.4836,  0.5522,  0.5908],\n",
      "       [-0.5273,  0.6113, -0.7407, -0.7603,  0.6914,  0.562 ,  0.5181,  0.0717,  0.2399,  0.6079,  0.5205,  0.5747],\n",
      "       [-0.7427,  0.7173, -0.8022, -0.8657,  0.9233,  0.729 ,  0.6392,  0.1593,  0.2332,  0.7036,  0.6152,  0.7031],\n",
      "       [ 0.1156,  1.1816, -0.1356, -0.1042, -0.3054, -0.1082, -0.1337,  2.3809,  2.8301, -0.5366, -0.1323, -0.4624],\n",
      "       [ 0.6509,  0.835 , -0.3218,  0.1069, -0.5239, -0.2625, -0.2874,  0.0775,  2.2441, -0.7441, -0.3306, -1.4033],\n",
      "       [ 0.3684,  0.5107, -1.0596, -0.7734,  0.194 ,  0.239 ,  0.2939,  0.194 ,  0.1575,  0.4985,  0.2375,  1.8721],\n",
      "       [-0.7183,  0.6343, -0.6807, -0.813 ,  0.8467,  0.6055,  0.5796,  0.1295,  0.3308,  0.5908,  0.6333,  0.626 ],\n",
      "       [-0.218 ,  0.77  , -0.8081, -1.0928,  0.2827,  0.3145,  0.2588,  0.2761,  0.0778,  0.1877,  0.3035,  0.8574]], dtype=float16), 'W_h': array([[-0.1385, -0.0456,  0.0477,  0.5903,  0.3374, -0.0149, -0.0293,  0.3479, -0.5376,  0.3538,  0.0728,  0.4519],\n",
      "       [-0.1155,  0.2483, -0.6943, -0.7998,  0.0217,  0.0406,  0.0876,  0.6826,  0.2776, -0.3711, -0.1035, -0.8208],\n",
      "       [ 2.2559, -0.3364, -0.7354,  0.6851, -0.4189, -0.0775, -0.0947,  0.8311, -0.8379, -1.29  , -0.2993, -1.0508],\n",
      "       [-2.7305, -0.2034, -0.1477, -1.668 ,  0.9102,  0.0931,  0.1058,  1.0176,  1.3066,  1.5586,  0.1324,  0.1713],\n",
      "       [ 1.0029, -0.1632, -0.2263,  0.5405, -0.044 ,  0.0393,  0.0638,  0.4905, -0.1827, -0.1362, -0.0356, -0.108 ],\n",
      "       [-1.9873,  0.1636, -0.4402, -1.2969,  0.3555, -0.003 , -0.0458, -0.081 ,  0.4182,  0.4124,  0.1207,  0.5571],\n",
      "       [-0.7368,  0.1465,  0.0571, -0.6152,  0.1273,  0.0552, -0.011 ,  0.236 ,  0.4963,  0.0141, -0.0231, -0.1714],\n",
      "       [ 0.4155,  0.1532, -0.3464, -0.5249, -0.373 , -0.0667, -0.0408, -0.5552,  0.8164, -0.897 , -0.1624, -0.519 ]], dtype=float16), 'b_h': array([-0.7388,  1.3232, -2.3047, -1.6934, -0.7705, -1.2012, -1.3789,  1.957 ,  1.5381,  0.1337, -1.3037, -0.8394], dtype=float16)}, 'softmax_params': {'W': array([[-0.1143,  0.8027, -0.1129, ...,  0.5962, -0.1141, -0.1157],\n",
      "       [ 0.0544,  2.7227,  0.1333, ..., -1.7949,  0.0586,  0.0638],\n",
      "       [-0.1328,  1.957 , -0.0701, ...,  0.8706, -0.0874, -0.1381],\n",
      "       ..., \n",
      "       [ 0.2057, -0.564 ,  0.1281, ..., -0.4832,  0.2007,  0.146 ],\n",
      "       [ 0.1405, -0.4001,  0.1757, ..., -0.2424,  0.2164,  0.192 ],\n",
      "       [ 0.1754, -0.4211,  0.1554, ..., -0.3027,  0.1473,  0.151 ]], dtype=float16), 'b': array([-0.4246,  0.2786, -0.3816,  1.9932, -0.4021,  0.1746,  0.4377,  0.3738, -0.3613,  0.6201, -0.3821, -0.4229, -0.3674, -0.3828, -0.3848, -0.4116,  0.3333, -0.3643, -0.4211,  0.9331,  0.1284,\n",
      "       -0.4106, -0.3679, -0.3882,  0.4277, -0.3579, -0.3816,  0.3049, -0.4165,  0.4836,  2.7656,  0.214 , -0.3757,  0.2491,  0.1614, -0.386 ,  0.4309, -0.3926,  0.1968,  0.9131, -0.4033, -0.4329,\n",
      "        0.6724, -0.4102, -0.407 ,  0.3794, -0.3594,  0.3721, -0.4368, -0.3813,  3.084 , -0.3542, -0.4167, -0.3765, -0.3723,  0.3352,  0.2457,  0.3594,  1.3213, -0.356 , -0.3728, -0.4309, -0.408 ,\n",
      "        0.2534, -0.4307, -0.3916, -0.4321, -0.3667,  0.3306,  2.6953, -0.4028, -0.3718, -0.4036, -0.4006, -0.4229, -0.4189,  0.6431,  0.3486,  0.2988,  0.2651, -0.366 , -0.3618,  0.3945, -0.3665,\n",
      "       -0.3708,  1.1582,  0.9111, -0.4319, -0.363 , -0.3855, -0.3994, -0.3962,  0.582 , -0.3889, -0.3665,  0.2125, -0.3611,  0.25  ,  0.325 ,  3.0059,  0.3745, -0.3918, -0.4077, -0.3557,  0.3423,\n",
      "       -0.4341, -0.3604, -0.376 ,  0.3472,  0.3843, -0.417 ,  0.8413,  0.3237, -0.3828, -0.3845, -0.4265, -0.4238, -0.3972, -0.4131, -0.4209, -0.4019, -0.415 , -0.3972, -0.374 , -0.3816,  0.2303,\n",
      "       -0.4316, -0.3701], dtype=float16)}}\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.randint(VOCAB_SIZE, size=(BATCH_SIZE, NUM_STEPS))\n",
    "targets = np.random.randint(VOCAB_SIZE, size=(BATCH_SIZE, NUM_STEPS))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        outputs = sess.run(\n",
    "            my_outputs['outputs'],\n",
    "            feed_dict={\n",
    "                my_rnn['inputs']['input_sequence']: inputs,\n",
    "                my_outputs['inputs']['targets']: targets,\n",
    "            }\n",
    "        )\n",
    "        if i % 100 == (100 - 1):\n",
    "            print(outputs['loss'])\n",
    "    params = sess.run(\n",
    "        my_rnn['params']\n",
    "    )\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([[[ 0.0208,  0.029 ,  0.0205, -0.0311,  0.0475,  0.0413, -0.0357,  0.0031],\n",
       "         [ 0.0209,  0.0296,  0.0206, -0.031 ,  0.0479,  0.0419, -0.036 ,  0.0027],\n",
       "         [ 0.0209,  0.0299,  0.0207, -0.0309,  0.0481,  0.0422, -0.0362,  0.0025],\n",
       "         [ 0.0209,  0.0301,  0.0206, -0.0309,  0.0482,  0.0424, -0.0361,  0.0023],\n",
       "         [ 0.0209,  0.0302,  0.0207, -0.0309,  0.0483,  0.0425, -0.0363,  0.0022]],\n",
       " \n",
       "        [[ 0.0208,  0.0291,  0.0206, -0.0311,  0.0475,  0.0414, -0.0359,  0.0031],\n",
       "         [ 0.0208,  0.0296,  0.0207, -0.031 ,  0.0478,  0.0419, -0.0362,  0.0027],\n",
       "         [ 0.0209,  0.03  ,  0.0206, -0.031 ,  0.0481,  0.0422, -0.0362,  0.0024],\n",
       "         [ 0.021 ,  0.0301,  0.0207, -0.0309,  0.0483,  0.0424, -0.036 ,  0.0022],\n",
       "         [ 0.021 ,  0.0302,  0.0208, -0.0309,  0.0483,  0.0425, -0.0362,  0.0022]],\n",
       " \n",
       "        [[ 0.0208,  0.029 ,  0.0205, -0.0311,  0.0475,  0.0413, -0.0356,  0.0031],\n",
       "         [ 0.0209,  0.0297,  0.0206, -0.031 ,  0.0479,  0.042 , -0.0362,  0.0026],\n",
       "         [ 0.0209,  0.03  ,  0.0206, -0.031 ,  0.0482,  0.0423, -0.0362,  0.0024],\n",
       "         [ 0.0209,  0.0301,  0.0206, -0.031 ,  0.0483,  0.0424, -0.0362,  0.0023],\n",
       "         [ 0.0209,  0.0302,  0.0207, -0.0309,  0.0483,  0.0424, -0.0361,  0.0022]],\n",
       " \n",
       "        [[ 0.0208,  0.029 ,  0.0206, -0.0311,  0.0474,  0.0413, -0.0358,  0.0031],\n",
       "         [ 0.0208,  0.0296,  0.0207, -0.0309,  0.0478,  0.0418, -0.0361,  0.0027],\n",
       "         [ 0.0209,  0.0298,  0.0207, -0.0309,  0.048 ,  0.0421, -0.0362,  0.0025],\n",
       "         [ 0.0209,  0.03  ,  0.0207, -0.0309,  0.0481,  0.0423, -0.0363,  0.0024],\n",
       "         [ 0.0209,  0.0302,  0.0208, -0.0309,  0.0482,  0.0425, -0.0363,  0.0022]]], dtype=float16),\n",
       " 'reshaped_states': array([[[ 0.006 ,  0.0214, -0.0181],\n",
       "         [ 0.0091,  0.0325, -0.0269],\n",
       "         [ 0.0101,  0.0365, -0.0318],\n",
       "         [ 0.01  ,  0.0413, -0.0331],\n",
       "         [ 0.0106,  0.0435, -0.0359]],\n",
       " \n",
       "        [[ 0.0077,  0.0201, -0.0201],\n",
       "         [ 0.0094,  0.0301, -0.0285],\n",
       "         [ 0.0109,  0.0375, -0.0319],\n",
       "         [ 0.0079,  0.0427, -0.033 ],\n",
       "         [ 0.0095,  0.0441, -0.0358]],\n",
       " \n",
       "        [[ 0.0049,  0.0222, -0.0175],\n",
       "         [ 0.0102,  0.0317, -0.0287],\n",
       "         [ 0.0111,  0.0379, -0.0322],\n",
       "         [ 0.0118,  0.0416, -0.0338],\n",
       "         [ 0.0097,  0.043 , -0.0336]],\n",
       " \n",
       "        [[ 0.0055,  0.0196, -0.0186],\n",
       "         [ 0.0083,  0.0298, -0.0277],\n",
       "         [ 0.0097,  0.0351, -0.0322],\n",
       "         [ 0.0104,  0.0379, -0.0344],\n",
       "         [ 0.0108,  0.0417, -0.0365]]], dtype=float16)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  6  7  8  9]\n",
      " [ 4  5  6  7 10 11 12 13]\n",
      " [ 8  9 10 11 14 15 16 17]]\n",
      "\n",
      "[[ 0  1  2  3]\n",
      " [ 6  7  8  9]\n",
      " [ 4  5  6  7]\n",
      " [10 11 12 13]\n",
      " [ 8  9 10 11]\n",
      " [14 15 16 17]]\n",
      "\n",
      "[[[ 0  1  2  3]\n",
      "  [ 6  7  8  9]]\n",
      "\n",
      " [[ 4  5  6  7]\n",
      "  [10 11 12 13]]\n",
      "\n",
      " [[ 8  9 10 11]\n",
      "  [14 15 16 17]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this example, batch_size is 3, hidden_size = 4, num_steps = 2\n",
    "m1 = tf.constant(np.reshape(np.arange(12),(3,4)))\n",
    "m2 = tf.constant(6 + np.reshape(np.arange(12),(3,4)))\n",
    "concatenated_ms = tf.concat([m1, m2], axis=1)\n",
    "skinny_ms = tf.reshape(concatenated_ms, [-1, 4])\n",
    "reshaped_ms = tf.reshape(skinny_ms, [-1, 2, 4])\n",
    "with tf.Session() as sess:\n",
    "    for m in sess.run([\n",
    "        concatenated_ms,\n",
    "        skinny_ms,\n",
    "        reshaped_ms\n",
    "    ]):\n",
    "        print(m)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 3 for 'MatMul_1' (op: 'MatMul') with input shapes: [2,3,4], [4,2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 3 for 'MatMul_1' (op: 'MatMul') with input shapes: [2,3,4], [4,2].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6a23eebed92f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1844\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \"\"\"\n\u001b[1;32m   1288\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1289\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1290\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3k/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 3 for 'MatMul_1' (op: 'MatMul') with input shapes: [2,3,4], [4,2]."
     ]
    }
   ],
   "source": [
    "m1 = tf.constant(np.reshape(np.arange(24),(2,3,4)), dtype=tf.float32)\n",
    "m2 = tf.constant(np.reshape(np.arange(8),(4,2)), dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.matmul(m1, m2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batcher/x:0\", shape=(4, 3), dtype=int32) Tensor(\"batcher/y:0\", shape=(4, 3), dtype=int32)\n",
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2]\n",
      " [ 50  51  52]\n",
      " [100 101 102]\n",
      " [150 151 152]]\n",
      "[[  1   2   3]\n",
      " [ 51  52  53]\n",
      " [101 102 103]\n",
      " [151 152 153]]\n",
      "[[  3   4   5]\n",
      " [ 53  54  55]\n",
      " [103 104 105]\n",
      " [153 154 155]]\n",
      "[[  4   5   6]\n",
      " [ 54  55  56]\n",
      " [104 105 106]\n",
      " [154 155 156]]\n"
     ]
    }
   ],
   "source": [
    "tf_x, tf_y = ptb_batcher(np.arange(200), 4, 3)\n",
    "print(tf_x, tf_y)sv = tf.train.Supervisor(logdir='logs')\n",
    "with sv.managed_session() as sess:\n",
    "    for i in range(2):\n",
    "        xout, yout = sess.run([tf_x, tf_y])\n",
    "        print(xout)\n",
    "        print(yout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('foo'):\n",
    "    with tf.name_scope('foo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
